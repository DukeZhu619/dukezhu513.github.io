---
title: 《Refining Adaptive Zeroth-Order Optimization at Ease》
date: '2025-12-07 23:56:47'
updated: '2025-12-08 01:06:44'
permalink: /post/refining-adaptive-zerothorder-optimization-at-ease-1gojwp.html
comments: true
toc: true
---



# 《Refining Adaptive Zeroth-Order Optimization at Ease》

## 1. 基本信息

- **作者 / 机构**：Yao Shu（港科大广州）、Qixin Zhang（南洋理工大学）、Kun He（华中科技大学）、Zhongxiang Dai（港中文深圳）
- **发表 Venue / 年份**：ICML 2025
- **论文链接**：arXiv:2502.01014v2
- **核心任务**：本文旨在解决自适应零阶优化（Adaptive ZO Optimization）中因高方差梯度估计导致的收敛缓慢问题，其根本症结在于现有方法（如 ZO-AdaMM）未能有效利用动量信息进行方差缩减，致使二阶矩估计失真，进而削弱自适应缩放的有效性。

## 2. 研究动机与问题定义

在黑盒对抗攻击、大语言模型（LLM）API微调等实际场景中，梯度不可用，零阶优化成为唯一可行方案。尽管自适应一阶方法（如 Adam）已在实践中取得巨大成功，但其零阶版本（如 ZO-AdaMM）的性能却远未达到预期。现有方法通常直接将一阶动量机制套用于零阶场景，忽视了零阶梯度估计器（如两点估计）固有的高方差特性：其方差与问题维度 $d$ 和平滑半径 $\mu$ 的倒数平方成正比，即 $\text{Var}[\hat{g}] \propto d / \mu^2$。

这种高方差直接污染了自适应优化器的二阶动量 $v_t$。在 ZO-AdaMM 中，$v_t$ 由原始高方差梯度估计 $g_t^2$ 更新，导致其对优化轨迹几何（landscape geometry）的刻画严重失真，从而产生过小的有效学习率，显著拖慢收敛。本文的核心洞察在于：**一阶动量** **$m_t$** **本身即是对历史梯度的指数移动平均，天然具备平滑噪声、降低方差的能力**。若能将此精炼后的 $m_t$ 用于构造二阶动量，即可获得更准确的几何信息，实现更有效的自适应更新。

## 3. 方法论深度解析 (The Heart of ZOO)

本文提出 **R-AdaZO**  ****(Refined Adaptive ZO) 算法，其核心创新在于一种****​**级联精炼**（Cascade Refinement）的动量利用机制。该机制包含两个紧密耦合的技术组件。

**第一组件是方差缩减的一阶动量**。R-AdaZO 维持标准的一阶动量更新：$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$。然而，与以往将其视为单纯的速度累积不同，本文首次从理论上严格证明了 $m_t$ 的方差相较于原始估计 $g_t$ 显著降低。具体而言，在坐标光滑（coordinate-wise Lipschitz）假设下，其方差上界为 $(1-\beta_1)\Sigma^2/(1+\beta_1)$，其中 $\Sigma^2$ 为原始梯度估计的方差。这一定量分析揭示了 $\beta_1$ 在方差与偏差间的内在权衡：增大 $\beta_1$ 可有效抑制方差，但会引入因历史信息滞后而产生的偏差。

**第二组件是基于精炼动量的二阶矩更新**。这是 R-AdaZO 的关键原创所在。算法摒弃了 ZO-AdaMM 中直接使用高方差 $g_t^2$ 的做法，转而采用方差缩减后的一阶动量来构建二阶矩：$v_t = \beta_2 v_{t-1} + (1-\beta_2) m_t^2$。这一精炼操作使得 $v_t$ 能够更准确地逼近其“无噪声理想态”——即真实梯度平方的指数移动平均。理论分析表明，该策略将二阶矩中与方差相关的项从 $(1+\beta_1)\Sigma^2$ 降至 $(1-\beta_1)\Sigma^2$，从而为后续的自适应缩放提供了更可靠的依据。

整个算法流程仅需对 ZO-AdaMM 进行一行代码修改，即二阶矩的更新源由 $g_t$ 改为 $m_t$，实现极为简洁，却能带来根本性的性能提升。

## 4. 实验设计与结果分析

实验在合成函数、MNIST 黑盒对抗攻击及 OPT 大语言模型微调三大任务上展开，全面验证了 R-AdaZO 的优越性。

在**查询效率**（Query Efficiency）方面，R-AdaZO 展现了压倒性优势。在 MNIST 黑盒攻击任务中，R-AdaZO 平均仅需 **2900 次查询**即可成功生成对抗样本，而 ZO-AdaMM 和 ZO-RMSProp 均需约 **15500 次**，提速达 **5.4 倍**。在 LLM 微调任务中，R-AdaZO 同样以更少的函数查询达到目标损失值，充分证明了其在高代价查询场景下的实用价值。

在**维度扩展性**上，R-AdaZO 的优势在高维（$d=10^4$）合成函数测试中得以保持，其收敛速度始终显著优于基线方法，表明该方法对**高维灾难**（Curse of Dimensionality）具有更强的鲁棒性。

**消融实验**进一步验证了理论分析。实验表明，性能随一阶动量系数 $\beta_1$ 的增大而提升，这与理论中“大 $\beta_1$ 有助于方差缩减”的结论完全一致。更重要的是，当将 R-AdaZO 的二阶矩更新方式退化为使用 $g_t^2$ 时，其收敛速度急剧下降，直接证明了二阶矩精炼机制的有效性与必要性。

## 5. 理论贡献与实践意义

**理论层面**，本文建立了首个**方差感知的自适应 ZO 收敛性分析框架**。在非凸、坐标光滑假设下，作者证明了 R-AdaZO 的收敛速率为：

$$
\frac{1}{T} \sum_{t=0}^{T-1} \mathbb{E}[\|\nabla F(\theta_t)\|] \leq \mathcal{O}(\epsilon^2) + \mathcal{O}(\epsilon \sqrt{V}) + \mathcal{O}(\mu \sqrt{d}),
$$

其中 $V$ 为二阶矩的方差项。关键突破在于，通过精炼机制，R-AdaZO 成功将 $V$ 中的主导因子由 $(1+\beta_1)\Sigma^2$ 优化至 $(1-\beta_1)\Sigma^2$，从而获得了比 ZO-AdaMM 更快的理论收敛速度。该框架首次将自适应 ZO 优化器的收敛性与动量估计的方差显式关联，为未来相关研究提供了坚实的理论基础。

**工程价值**方面，R-AdaZO 具备极高的部署友好性。其实现仅需对现有自适应 ZO 优化器进行微小修改，无额外计算或内存开销，即可即插即用地提升性能。这一特性使其特别适用于**查询代价高昂的黑盒优化场景**，如商用大模型 API 的高效微调、科学实验中的参数搜索等。

## 6. 批判性评价与局限

尽管 R-AdaZO 取得了显著进展，但仍存在若干局限。首先，其收敛性证明依赖于**平滑半径** **$\mu$** **的选择**。理论要求 $\mu$ 随迭代逐渐减小以消除偏差项 $\mathcal{O}(\mu \sqrt{d})$，但在实践中常采用固定 $\mu$，这可能限制其在极高精度需求下的表现。其次，理论分析建立在**坐标光滑**（coordinate-wise Lipschitz）这一假设之上，对于具有强不连续性或病态条件数的黑盒函数，理论保证可能不成立。

在实验方面，论文虽覆盖了从低维到高维的广泛场景，但未测试**极端高维**（$d > 10^6$）情形下的性能，也未与**基于种群的搜索方法**（如 CMA-ES）进行对比，后者在处理复杂非凸景观时可能更具鲁棒性。这些均为未来值得探索的方向。

‍
